# -*- coding: utf-8 -*-
"""CW Q1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/128FOnjq76wpZhWMzt7QkC64rXlwzZU54

## Introduction
this notebook goes through some some non neural networking methods to work through our data and process it
we will be using a credit card fraud detection data set
mainly we look to use Logistic Regression due to  its simplicity, interpretability, and suitability for binary classification tasks.
We will aswell use SMOTE to deal with class imbalance

First we import the libraries we will be needing
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
import kagglehub

"""Download and define a fuction to import our data set"""

# this first two lines of code are taken from the data page to allow us to import the data set directly from the data base instead of haveing to manually download it and reupload it onto our drive
path = kagglehub.dataset_download("mlg-ulb/creditcardfraud")
print("Path to dataset files:", path)


# Define Helper Function to Import Data
def get_data(file_path):
    """
    Function to load and preprocess the Credit Card Fraud dataset.

    Args:
        file_path (str): Path to the CSV file.

    Returns:
        X_train, X_test, y_train, y_test: Preprocessed training and testing data.
    """
    # Loading the data
    data = pd.read_csv(file_path)
    print(data.head())
    print(data.info())
    print(data['Class'].value_counts())  # Check for class imbalance


    # Drop irrelivant column and separate features and targets (x) and (y)
    X = data.drop(columns=['Time', 'Class'])
    y = data['Class']


    # Normalize the 'Amount'
    scaler = StandardScaler()
    X['Amount'] = scaler.fit_transform(X[['Amount']])


    # Split the data into two, training set and testing set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)


    # Use SMOTE for class imbalance
    smote = SMOTE(random_state=42)
    X_train, y_train = smote.fit_resample(X_train, y_train)

    return X_train, X_test, y_train, y_test

"""Test the data set to ensure that it has been loaded properly"""

file_path = f"{path}/creditcard.csv"  # Use kagglehub's downloaded file path
X_train, X_test, y_train, y_test = get_data(file_path)#processes our data by runing it trhrough  the function

"""## Dataset Description
The dataset contains anonymized transaction features (`V1` to `V28`),  with `Time`, `Amount`, and `Class` for each transaction.  
- The dataset is mixed up, with fraud cases accounting for an minoratiy of all transactions.
"""

#  this line of code trains the Logistic Regression Model with the parameters we want and ensurs reproducibility
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train, y_train)


# we use the trained model to make predictions for our tests
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]



# we dispplay each class to make sure the code is working properly
print("Classification Report:")
print(classification_report(y_test, y_pred))


# shows the validity of our prediction in comparison to the actual data
print("Confusion Matrix:")
conf_matrix = confusion_matrix(y_test, y_pred)
print(conf_matrix)


# shows us how capable is our model of distingushiong between classes
roc_auc = roc_auc_score(y_test, y_pred_proba)
print(f"ROC-AUC Score: {roc_auc:.4f}")

"""visually represent our data set to help catagorise it"""

# visual reprentation of our data in the form of a heatmap and make the confusion Matrix more presentable
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Non-Fraud", "Fraud"], yticklabels=["Non-Fraud", "Fraud"])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""We use our data to plot a ROC curve"""

#Gives us an ROC curve
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
plt.figure(figsize=(6, 4))
plt.plot(fpr, tpr, label=f"Logistic Regression (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], 'k--')  # Dotted line
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

"""## Conclusion
Logistic Regressiongood a strong baseline for the fraud detection problem.  
However its linear decision boundary limit its application to more complex patterns of data.  


"""